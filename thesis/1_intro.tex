\chapter{Introduzione}
Al giorno d'oggi cercare informazioni sul web è diventata una delle operazioni più comuni e più richieste:
utilizzare lo smartphone per eseguire una ricerca sui punti di interesse di una città, o per scoprire la ricetta di un dolce è capitato quasi a tutte le persone.
Le statistiche elaborate direttamente da Google affermano che ogni secondo vengono richieste circa \textit{40.000} query, per un totale
giornaliero di \textit{3,5 miliardi}.
Siamo arrivati persino a parlare di memoria \textit{transattiva}, ovvero di una memoria condivisa tra tutti gli utenti e disponibile attraverso il web.
Ogni essere umano che possiede un qualunque mezzo tecnologico è in grado di accedervi in svariati modi, per esempio facendo una ricerca tramite Siri, Google oppure Alexa.
Tale memoria non consiste nel memorizzare l'informazione stessa, ma in come giungere ad essa.
Non è solo all'interno del web che c'è la necessità di un sistema di ricerca. Si pensi per esempio a Spotlight di Mac OS che
viene utilizzato per reperire informazioni da file di testo, audio, immagini e anche news dalla rete.

Il ruolo dell'Information Retrieval al giorno d'oggi è dunque di fondamentale importanza.
Per questo c'è stata la necessità di sviluppare gli algoritmi in tutte le dimensioni, a partire dall'architettura delle macchine sulle quali i documenti vengono archiviati a come i documenti stessi vengono strutturati.

In questa tesi di tirocinio verrà illustrato \textit{Terrier}: una piattaforma sviluppata dall'università di Glasgow
per sperimentare gli algoritmi legati all'Information Retrieval, anche su collezioni di dati nell'ordine dei terabyte.  Successivamente il focus si sposterà
sugli algoritmi di ranking, dei quali sarà utilizzato BM25P, una versione di BM25 migliorata dal gruppo ISTI del CNR di Pisa.
Verranno illustrati una serie di algoritmi il cui scopo è quello di ricercare, all'interno di uno spazio multidimensionale,
gli \textit{iperparametri} di BM25P, incrementando dunque le prestazioni rispetto a BM25 stesso.

Attraverso dei test statistici si dimostrarà infine che i due modelli di ranking sono decisamente diversi ed è possibile
inferire in quali parti (\textit{passages}) del documento sono contenute le informazioni più \textit{rilevanti}
e questo varierà in base al tipo di collezione di testi.

\section{Architettura generale}
In questo capitolo verrà illustrata l'architettura generale di un sistema di IR (\textit{Information Retrieval}) e verranno
descritti alcuni processi che sono stati oggetto di studio del tirocinio.

Quando si parla di sistema di IR, oppure in termini più quotidiani di motore di ricerca,
siamo spesso abituati a vederlo come un meccanismo di interrogazione dove l'utente
digita come input un testo, chiamato query e il motore risponde con una serie di risultati. Tali risultati
sono visualizzati dall'utente come una lista di documenti che contengono informazioni
rilevanti secondo la query.
\`E immediato pensare all'esempio di Google, dove il fruitore digita una serie di termini
all'interno del  form e dopo qualche secondo gli vengono restituiti tutti i link a pagine web, che
sono in qualche modo collegate a ciò che l'utente stava realmente cercando.
Quello che sta dietro a tutto questo processo, che sembra essere quasi immediato nell'esempio di Google, è
in realtà un lavoro molto complesso e lungo.
La fase in cui l'utente è abituato ad essere partecipe è quella finale, ovvero
il \textit{recupero}; ma prima di poter parlare di ciò è necessario illustrare la fase primaria, l'\textit{indicizzazione}.

\paragraph{Alcune definizioni}
Per essere più chiari, conveniamo alcune definizioni di termini tecnici che in altri contesti possono essere attribuiti
a concetti diversi.

\begin{definizione}\label{def:token}
	Un token è un'istanza di una sequenza di caratteri, in un documento $d \in \mathcal{D}$, che
	sono raggruppati tra di loro come un'unità semanticamente utile.
\end{definizione}

\begin{esempio}[tokenizzazione]
	Nella frase "Nulla si crea, nulla si distrugge ma tutto si trasforma" i token sono i seguenti:
	\tokenbox{nulla} \tokenbox{si} \tokenbox{crea} \tokenbox{nulla} \tokenbox{si} \tokenbox{distrugge}
	\tokenbox{ma} \tokenbox{tutto} \tokenbox{si} \tokenbox{trasforma}.
\end{esempio}

Un altro concetto importante è quello di \textit{tipo}.

\begin{definizione}[tipo]\label{def:tipo}
	Un tipo è una classe di token con la solita sequenza di caratteri.
\end{definizione}
\begin{esempio}
	Consideriamo la frase dell'esempio precedente. I tipi sono 7, mentre i token sono 10. Abbiamo dunque
	3 token che si ripetono.
\end{esempio}
\begin{definizione}[query]\label{def:query}
	Una query è un multinsieme di token, che rappresenta l'input che il motore di ricerca
	riceve dall'utente. 
\end{definizione}

\begin{esempio}
	Se si volessero cercare dei manuali tecnici sul linguaggio Python, si potrebbe esprimere 
	tale necessità attraverso la query $q$: \tokenbox{manuali} \tokenbox{python}.
	\\
	\\
	Un altro esempio potrebbe essere quello di voler ricercare i componenti
	elettronici inventati nel 1950. La query potrebbe essere $q$ : \tokenbox{componenti}
	\tokenbox{elettronici} \tokenbox{1950}.
\end{esempio}

Da notare che il concetto di multinsieme deriva dal fatto che si vuole tenere traccia in modo esplicito 
della molteplicità dei token nella query stessa.

\paragraph{Fase di indicizzazione}
Per poter offrire quella velocità che si richiede durante la fase di \textit{recupero} è necessario: aver ``preparato"
una struttura dati che sia completa, ovvero che comprenda tutte le informazioni necessarie e 
rapida da scorrere, cioè che le informazioni che si stanno cercando devono poter essere recuperate
il prima possibile.  Un esempio abbastanza esplicativo è quello dell'addetto alla biblioteca che deve rispondere
alle richieste degli studenti. Se egli non conoscesse i libri che sono parte della biblioteca, per ogni richiesta
dovrebbe scorrere tutta la lista e capire se quel dato libro può essere utile oppure no.
Questo esempio rappresenta il fatto che l'addetto non è in possesso di una struttura in grado
di accedere solo alle informazioni necessarie ed è dunque inefficiente.
Se quindi non ci fosse un indice, per un motore di ricerca sarebbe troppo dispendioso elaborare tutti
i documenti ``su richiesta".
La fase di \textit{indexing} ha lo scopo di costruire una struttura dati, chiamata indice, che consenta
di velocizzare la fase successiva, il \textit{recupero}.

Dal punto di vista delle prestazioni tale fase è quella con il  dispendio computazionale
più elevato, sia in termini di spazio che di tempo.
Questo perché si devono analizzare tutti i documenti della collezione ed eseguire una serie di elaborazioni
su di essi.

Il seguente algoritmo illustra in modo abbastanza basico ma intuitivo, la funzione eseguita dall'indexer.
\begin{algorithm}[h]
	\small
	\DontPrintSemicolon
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\Input{$\mathcal{D} $ collezione di documenti}
	\Output{$\mathcal{I}$ indice}
	\BlankLine
	$\mathcal{I} = generateEmptyIndex()$\;
	\ForEach{$d \in \mathcal{D}$}{
		$tokenizer = getTokenizer(d)$\;
		\While{$token = tokenizer.nextToken()$}{
			$n = normalizeToken(token)$\;
			$updateIndex(\mathcal{I}, n, d)$\;
		}
	}
	\Return{$\mathcal{I}$}
	\caption{\textsc{}}
	\label{alg:indexing}
\end{algorithm}
L'idea alla base è quella di rappresentare un documento come un flusso di token, il che è sempre possibile
poiché conveniamo che in questo campo dell'IR i documenti sono solo di tipo testuale.
Il token prima di essere passato alla funzione $updateIndex$ viene normalizzato. La normalizzazione è un processo
che si occupa di risolvere alcuni problemi legati al riconoscimento di  quando due token sintatticamente diversi
hanno invece la solita semantica.\footnote{Potrebbe essere necessario uno step in più per risolvere il problema della codifica, poiché alcune lingue posseggono caratteri che non tutte le codifiche hanno. Per esempio le lingue cirillica e cinese.}

Tale processo può essere schematizzato nel seguente modo, dove a sinistra viene indicato
il nome della normalizzazione e a destra una breve descrizione.

\begin{itemize}
	\item[\textbf{Casing:}] le lettere maiuscole vengono convertite in minuscole oppure viceversa, in base al tipo di convenzione utilizzata.
	\item[\textbf{Accenti:}] le parole con accenti vengono convertite in parole senza accenti.
	\item[\textbf{Lemmatizzazione:}] vengono convertite le forme flesse delle parole in una forma canonica, cioè nel lemma.
\end{itemize}

\begin{esempio}[normalizzazione]
	Sia data la seguente frase: ``\textit{Mi piacciono tutte le auto che sono elettriche}".
	Utilizzando le tecniche elencate in precedenza, i token normalizzati risultano:
	\tokenbox{Mi} \tokenbox{piacere} \tokenbox{tutte} \tokenbox{le} \tokenbox{auto}
	\tokenbox{che} \tokenbox{essere} \tokenbox{elettriche}.
\end{esempio}

\subparagraph{Indice invertito}
Una volta che il token è stato normalizzato si procede all'aggiornamento dell'indice, ovvero alla costruzione (o aggiornamento)
dell'indice invertito. Tale struttura è definita come una lista di coppie
$\langle token, postingList \rangle$ dove postingList è una lista di \textit{identificatori di documenti}.
In questo modo possiamo capire il token $x$ in quali documenti è contenuto, cercando dentro l'indice
invertito la posizione di $x$ e accedendo alla sua \textit{postingList}.

\begin{figure}[h]
	\label{fig:invertedIndex}
	\centering
	\includegraphics[scale=0.4]{InvertedIndex.eps}
\end{figure}

\pagebreak

Ritornando all'esempio della biblioteca, se l'addetto avesse a disposizione l'indice invertito potrebbe:
\begin{enumerate}
	\item raccogliere la query $\mathcal{Q}$ dello studente
	\item normalizzare $\mathcal{Q}$
	\item $\forall t.t\in Q$ cercare all'interno dell'indice invertito il termine $t$ e \textit{ritornare} la \textit{postingList} associata
\end{enumerate}

In questo modo tutti i documenti che contengono almeno una volta un termine della query verrebbero mostrati
agli studenti, ma ovviamente non tutti possono essere rilevanti per la ricerca. Il problema dunque si è ridotto
a come utilizzare l'indice invertito per capire quanto la query sia associata al documento in questione ed è per questo
motivo che viene introdotta la fase di \textit{recupero}.

\paragraph{Fase di recupero}
Lo scopo della fase di \textit{recupero} è quello di utilizzare l'indice invertito e affinare il modo con cui
i documenti vengono proposti all'utente. Tali documenti sono comunemente chiamati \textit{risultati}.
Il processo prende anche il nome di \textit{ranking}, poiché l'idea alla base è quella di attribuire
un punteggio ad ogni risultato e costruire una lista ordinata in senso crescente.
Ovviamente il primo risultato è quello nel quale il sistema di ranking è più
rilevante per la query $q$. Tale processo viene fatto ogni volta che l'utente
interroga il sistema, per cui deve essere veloce, efficiente ed efficace.

L'articolo \cite{10.1016/j.ipm.2016.05.004} mostra una serie di tecniche che possono essere
utilizzate per valutare il compromesso tra qualità di un ranker ed efficienza, 
alcune delle quali sono state utilizzate nell'ambito di questo tirocinio.\\
Per essere più precisi possibile, possiamo definire la funzione di \textit{scoring} nel seguente modo:

\begin{definizione}\label{def:funzione_di_score_ideale}
	Una funzione di scoring ideale $f(d,q) : \mathcal{D} \times \mathcal{Q} \rightarrow \mathbb{R}$ è tale
	se e solo se
	$$
	f(d_1,q_1) \geq f(d_2, q_2) \implies \rel_B(d_1, q_1) \geq \rel_B(d_2, q_2)
	$$
dove $\rel_B(d,q)$ è la rilevanza del documento $d$ per la query $q$, calcolata a priori.	
\end{definizione}

Tale definizione delinea una funzione di scoring ideale, per la quale non esiste un algoritmo che
la calcoli. Possiamo però accontentarci di funzioni che la approssimino, facendo uso di euristiche basate sulla statistica.

Lo scopo di $f$ può esser visto anche come quello di produrre un elenco ordinato il più possibile uguale a quello
che produrrebbe la funzione $\rel_B$. Ciò comporta che anche se i valori di $f$ sono scalati rispetto a quelli di $\rel_B$,
$f$ rappresenterebbe comunque una buona approssimazione.

\begin{esempio}
	Sia $\mathcal{L}= \left\{d_1, d_3, d_5, d_6, d_8 \right\}$ l'elenco ordinato prodotto
	dalla funzione ideale di scoring secondo una query $q$. Applicando $\rel_B$ ad esso si ottiene dunque la seguente catena
	di disuguaglianze: \footnote{La funzione $\rel_B$, nell'esempio in questione, non è stata provvista del parametro $q$ per semplicità di trattazione.}
	
	$$
	\rel_B(d_1) \geq \rel_B(d_3) \geq \rel_B(d_5) \geq \rel_B(d_6) \geq  \rel_B(d_8)
	$$
	
	\`E possibile trovare adesso una funzione che assuma valori diversi da $\rel_B$, ma che produca il solito ordine,
	ad esempio:
	
	\begin{align*}
	\rel_B(\mathcal{L}) = \left\{1, 1, 1, 0, 0\right\} \\
	f(\mathcal{L}) = \left\{8, 8, 7, 3, 1\right\}
	\end{align*}
	
\end{esempio}

\pagebreak

Nei prossimi capitoli verranno descritte le funzioni di scoring che propongono BM25 e BM25P, le quali si basano sul concetto di \textit{Term Frequency} e \textit{Inverse Document Frequency}.
Prima di concludere la visione generale diamo la definizione di alcuni concetti che sono utilizzati durante il \textit{recupero}.

\begin{definizione}[Raw Count]\label{def:raw_count}
	$\rc(q, d) : \mathcal{Q} \times \mathcal{D} \rightarrow \mathbb{N}$ è detto raw count, cioè il numero di volte che
	il termine q occorre nel documento $d$.
\end{definizione}

\begin{definizione}[Term Frequency]\label{def:}
	La funzione $\tf(q,d)$, acronimo di Term Frequency, è una funzione che calcola la frequenza del
	termine $q \in \mathcal{Q}$ nel documento $d \in \mathcal{D}$.
	Tale valore si discosta da quello di $rc$, poiché solitamente è normalizzato o in scala logaritmica
	oppure in base alla lunghezza del documento.
	
	\begin{itemize}
		\item $\tf(q,d) = \log_{k}(1+\rc(q,d))$ con $k>1$
		\item $\tf(q,d) = \frac{rc(q,d)}{|d|}$ dove $|d|$ è il numero totale di token nel documento
	\end{itemize}
\end{definizione}

\begin{definizione}[Inverse Document Frequency]\label{def:idf}
	$$
	\idf(q, \mathcal{D}) = \log_{k>1}{
		\frac{\#\mathcal{D}}{
			\#
			\left\{
			d \in \mathcal{D} \middle \lvert rc(q,d) > 0
			\right\} 
		}
	}
	$$
	
	Tale misura esprime quanta informazione una parola, o più un generale un token, fornisce.
	Può essere anche vista come la misura della rarità, cioè quanto è comune il termine $q$
	nella collezione di documenti $\mathcal{D}$.
\end{definizione}




