\chapter{Metriche}

In questo capitolo si  illustreranno alcune tecniche 
per valutare un modello di pesi e dunque poterlo confrontare con gli altri.
\'E di necessaria importanza poterlo fare perché nel capitolo sull'ottimizzazione di BM25P dovremo avere un modo per eseguire
la cosidetta fase di \textit{model selection}. Dovremo cioè valutare se un modello con un iperparametro $\lambda$ è
migliore rispetto a un modello con un iperparametro $\lambda' \neq \lambda$.

Ma in generale per valutare le prestazioni di un motore di ricerca possiamo usare due unità di misura:

\begin{itemize}
	\item La \textbf{qualità}, intesa come l'effettività, cioè quanto il motore di ricerca
	è in grado di mostrare all'utente documenti che siano rilevanti con la query $q$.
	\item L'\textbf{efficienza}, cioè quanto tempo viene impiegato nel calcolo dei risultati, quindi in questo caso
	quanto tempo impiega la fase di \textit{retrieval}.
\end{itemize}

L'obiettivo di questo tirocinio è stato quello di massimizzare la qualità di BM25P, pertanto
la seconda unità di misura non è rilevante, anche perché variando il valore di un iperparametro
non si hanno ripercussioni notevoli sull'efficienza, ma solo sulla qualità.

Per poter valutare l'effettività è necessario riprendere il concetto di rilevanza  che era stato
accennato nel capitolo 1. Essa purtroppo è una misura non del tutto oggettiva,
poiché un utente potrebbe decidere che la query $q$ e il documento $d$ siano
in qualche modo collegati tra loro o meno.

\begin{esempio}
	Sia $q$ la query \textit{``python"}. L'utente potrebbe intendere sia il linguaggio di programmazione Python
	che l'animale stesso. Dunque se questa query fosse sottomessa a un motore di ricerca
	esso potrebbe ritornare al fruitore entrambi i risultati, che a seconda della necessità
	potrebbe valutarli come rilevanti oppure no.
\end{esempio}

Ciò che l'utente intende è chiamata \textit{Information Need}, cioè la richiesta di informazione
che si tenta di esprimere sottomettendo una query al sistema di ricerca.

La soggettività di questa valutazione è uno dei punti cruciali dell'Information Retrieval, per cui non esistono
metodi matematici per calcolarla ed è necessario l'intervento umano.
Viene enunciata dunque la definizione di rilevanza booleana:

\begin{definizione}\label{def:relb}
	La rilevanza booleana $\rel_B(d,q): \mathcal{D} \times \mathcal{Q} \rightarrow \mathbb{B}$
	è una funzione binaria che associa alla coppia query-documento un valore booleano
	true o false, in questo modo:
	\begin{itemize}
		\item		$\rel_B(d,q) = true$ se e solo se l'utente ritiene che il documento d è rilevante
		per la query $q$.
		\item $\rel_B(d,q) = false$ altrimenti.
	\end{itemize}
	
	Anche se ovvio, sottolineamo il fatto che $\rel_B(q,d)$ dipende unicamente dalla query q e
	dal documento $d$. In altri contesti questo concetto può esser chiamato anche con il nome
	di \textit{ground truth} oppure \textit{gold standard}.
\end{definizione}

Il valore di tale funzione deve sempre esser calcolato da un essere umano, poiché come da definizione, 
deve rappresentare una verità soggettiva.

Ciò potrebbe sembrare però un po' limitante, poiché quando si parla di scoring,
$\sco(q,d)$ restituisce valori continui in $\mathbb{R}$ e dunque come può
approssimare $\rel_B$?
La risposta sta nel fatto che un ranker $\mathcal{R}$ si limita ad ordinare i documenti utilizzando come peso
il valore attribuito al documento dalla funzione $\sco$. Pertanto se ipotizzassimo di prendere
i primi $k$ elementi dalla lista $\mathcal{L}$, restituita dal motore di ricerca, potremo affermare che:

\begin{itemize}
	\item Se $d \in \mathcal{L}$  allora $\rel_{\mathcal{R}}(d, q) = true$
	\item Se $d \notin \mathcal{L}$ allora $\rel_{\mathcal{R}}(d,q) = false$
\end{itemize}

Attraverso questa definizione siamo in grado dunque di stabilire le modalità di valutazione di
un motore di ricerca, poiché possiamo paragonare i risultati di $\rel_B$ con quelli di $\rel_{\mathcal{R}}$,
ottenendo dunque un meccanismo di comparazione tra i risultati attesi e quelli calcolati.

\subsection{Il principio PRP}

In questo paragrafo viene introdotto il \textit{Probability Ranking Principle}, ovvero un risultato
teorico che ci consenta di avere una base matematica per valutare l'ottimalità di un ranker.
Tale principio afferma che:

\begin{definizione}\label{def:prp}
	Se per ogni query $q \in \mathcal{Q}$ il sistema ordina i documenti della collezione $\mathcal{D}$ in
	senso decrescente rispetto alla probabilità di rilevanza, allora l'effettività complessiva del sistema
	è la migliore ottenibile con i dati a disposizione.
\end{definizione}

Questo principio rappresenta l'unico metodo formale per verificare l'effettività di un sistema
di ricerca, poichè migliore è la stima della rilevanza, migliori saranno le prestazioni.

Per completezza della trattazione dell'argomento verrà data di seguito
un'illustrazione di come dimostrare questo principio.

\begin{proof}
	Iniziamo la dimostrazione procedendo per punti:
	\begin{itemize}
		\item Sia $\mathcal{R}$ un ranker
		\item Siano $\mathcal{Q}$ e $\mathcal{D}$ gli insiemi delle query e dei documenti
		\item In questo contesto, sia $\rel_\mathcal{R}$ una variabile con natura aleatoria
		\item $\forall{q \in \mathcal{Q}, d \in \mathcal{D}}$ sia $P(\rel_B = r  | D = d, Q = q )$
		la probabilità che il documento $d$ sia rilevante per $q$.
		\item Sia $\mathcal{L}$  la lista ordinata dei documenti ritornati dal motore di ricerca, di lunghezza arbitraria
		$k$.
	\end{itemize}
	
	Il valore atteso della rilevanza possiamo calcolarlo come:
	\begin{align*}
	& \mathbb{E}\left[\rel_B\right] = \sum_{i=1}^{k}{
		1 \cdot P(\rel_B = true  | D = d_i, Q = q ) + \cancelto{0}{0 \cdot  P(\rel_B = false  | D = d_i, Q = q )}
	} \\
	& \mathbb{E}\left[\rel_B\right] = \sum_{i=1}^{k}{P(\rel_B = true  | D = d_i, Q = q )}
	\end{align*}
	
	Ciò che vogliamo dimostrare è che per ogni valore di $k>0$, il valore atteso è massimo quando i documenti
	sono ordinati in senso decrescente.
	Procediamo dunque per assurdo ipotizzando esista un valore $\tilde{k}$ tale che $\mathbb{E}[\rel_B]$ sia
	massimo anche se i documenti non sono ordinati in tal modo.
	Si verifica dunque che esiste almeno un documento $d_l$ che non viene inserito in $\mathcal{L}$ nell'ordinamento
	decrescente e inoltre ciò impone che un altro documento $d_m$ non venga inserito nell'ultima posizione della lista.
	Abbiamo quindi che:
	$$
	P(\rel_B = r | D = d_l, Q=q)  < P(\rel_B = r| D = d_m, Q = q)
	$$
	
	e dunque:
	
	\begin{align*}
	& \mathbb{E}\left[\rel_B\right]_{\tilde{k}} = \sum_{i=1}^{\tilde{k}}{P(\rel_B = true | D = d_i, Q = q)} \\
	& \mathbb{E}[\rel_B]_{\tilde{k}} \Big|_{d_{\tilde{k}} = d_{l}} < \mathbb{E}[\rel_B]_{\tilde{k}} \Big|_{d_{\tilde{k}} = d_{m}}
	\end{align*}
	
	Ciò però è assurdo, perché per ipotesi $\mathbb{E}\left[\rel_B\right]_{\tilde{k}}$ sostituendo $d_{\tilde{k}}$ con $d_l$ doveva
	essere massimo.
\end{proof}

\section{Recall e Precision}

Adesso che abbiamo raccolto tutte le informazioni necessarie possiamo definire
le unità di misura che descrivono la qualità di un motore di ricerca.
Le misure più semplici che sono adottate attualmente sono  la \textit{recall} e la \textit{precision}.

\begin{definizione}\label{def:recall}
	La recall, indicata con il simbolo $\re$, è definita come il rapporto tra il numero di documenti
	messi in lista da  un ranker $\mathcal{R}$, per cui $\rel_B(d,q) = true$,
	e il numero di elementi totali giudicati rilevanti.
	In simboli si ha:
	
	$$
	\re = P(d \in \mathcal{L} | \rel_B(d,q) = true) = \frac{
		\#\left\{ d \in \mathcal{L} | \rel_B(d,q) = true\right\}
	}{
		\#\left\{ d \in \mathcal{D} | \rel_B(d,q) = true\right\}
	}
	$$
\end{definizione}

Ovviamente affinchè la recall sia massima, il ranker dovrebbe ritornare la lista di tutti i documenti
rilevanti, ma questo non sempre risulta possibile, poiché $\left|\mathcal{L}\right| \lll \left|\mathcal{D}\right|$.

\begin{definizione}\label{def:precision}
	La precision, indicata con il simbolo $\preci$, è uguale alla recall
	ma con la differenza che il rapporto non ha come denominatore tutti i documenti
	rilevanti, ma solo quelli in lista.
	
	$$
	\re = P(d \in \mathcal{L} | \rel_B(d,q) = true) = \frac{
		\#\left\{ d \in \mathcal{L} | \rel_B(d,q) = true\right\}
	}{
		\left|\mathcal{L}\right|
	}
	$$
\end{definizione}
Invece per precision, raggiungere il valore massimo è abbastanza facile, specialmente quando $\left|\mathcal{L}\right| \approx 1$.

\pagebreak

Un modo analogo per calcolare $\re$ e $\preci$ è quello di creare una sorta di matrice di contingenza, nel seguente modo:

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		& $\rel_b = true$ & $\rel_b = false$ \\
		\hline
		$d \in \mathcal{L}$ &  vero positivo (tp) & falso positivo (fp) \\
		\hline
		$d \notin \mathcal{L}$ &  falso negativo (fn) & vero negativo (tn) \\
		\hline
	\end{tabular}
	\caption{Matrice di contingenza, o matrice di confusione}
\end{table}

Una volta avvalorata la matrice, si può calcolare $\preci = \frac{tp}{tp + fp}$ e $\re = \frac{tp}{tp + fn}$.

\paragraph{Il problema delle misure}
Il problema principale di queste due misure è il fatto che statisticamente il $99.9\%$\cite{irbook} dei documenti
risulta non rilevante per una query $q$. 
Infatti se la funzione obiettivo da massimizzare fosse recall,
un sistema che marca tutti i documenti come non rilevanti avrebbe
un valore molto vicino ad un sistema che invece funziona bene. Inoltre
queste misure sono basate sull'insieme dei documenti restituiti e non tengono
conto dell'ordine della lista $\mathcal{L}$.

Per esempio un utente che naviga nel web è interessato
ad avere come primo risultato esattamente il documento che stava cercando
e non vorrebbe scorrere i risultati fino a trovare quello che gli interessava.
Precision e recall quindi sono misure semplici ed effettive, ma non
complete per la valutazione di un motore di ricerca.

\section{NDCG}
L'unità di misura che andremo a considerare è la Normative Discontinued Cumulative Gain,
definita come segue:

$$\label{def:ndcg}
NDCG(O, k) = \frac{1}{\left|O\right|} \sum_{q \in O} Z_{k, q} \cdot \sum_{i=1}^{k} \frac{2^{R(d_i, q)} - 1}{\log_2{(i + 1)}} \\
$$

in cui abbiamo che:
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		$ O \subset Q$ & è un sottoinsieme di query \\
		\hline
		$Z_{k,q}$ & è il fattore di normalizzazione \\
		\hline
		$R(d,q)$ & è il gold standard, possiamo assumerla uguale a $\rel_B$ \\
		\hline
	\end{tabular}
\end{table}

Come è possibile notare dalla formula, in questo modo andiamo a considerare un sottoinsieme delle query, che chiamiamo $O$,
e un intero $k>1$ che conta il numero di documenti nella lista $\mathcal{L}$.

Espandendo la seconda sommatoria $s_2$ è interessante notare che:
$$
s_2 = \frac{2^{R(d_1, q) } - 1}{1} + \frac{2^{R(d_2, q)} - 1}{1.58} + \frac{2^{R(d_3, q)} - 1}{2} + \dotsb + \frac{2^{R(d_k, q) } - 1}{\log_2{k + 1}}
$$

Siccome la funzione $log_2(x)$ è monotona crescente, $s_2$ è costruita in modo tale da
premiare maggiormente i risultati con $k$ piccolo e penalizzare quelli con $k$ più grande.
Parlando anche in termini computazionali, calcolare il valore dell'esponente al numeratore
non è troppo dispendioso poiché:

\begin{enumerate}
	\item la base dell'esponente è 2 e il valore di $R(d,q)$ è intero, dunque si può fare bit shifting;
	\item la funzione $R(d,q)$ inoltre, se la ipotizziamo uguale a $\rel_B$ assume solo due valori,
	o anche se fosse diversa essa assumerebbe un insieme finito di valori che può essere precomputato.
\end{enumerate}

La prima parte della formula invece non fa altro che calcolare una media aritmetica
dei singoli valori ottenuti valutando una query. Infatti è possibile semplificarla
nel caso in cui si voglia calcolare la valutazione rimuovendo la prima parte, come verrà fatto
negli esempi successivi.

\begin{esempio}[Calcolo di DCG]\label{eg:dcg}
	Ipotizziamo di calcolare il valore di DCG (NDCG non normalizzata) avendo a disposizione:
	\begin{itemize}
		\item i risultati $\mathcal{L} = \left\{r_1, r_2, r_3, r_4\right\}$, ordinati per rank,
		\item le rilevanze associate ai risultati, cioè $\rel_B\left(\mathcal{L}\right) = \left\{1, 0, 0, 1\right\}$
	\end{itemize}

$$
DCG = \frac{2^{1} - 1}{1} + \frac{2^{0} - 1}{1.58} + \frac{2^{0} - 1}{2} + \frac{2^{1} - 1}{2.32} = 1.43
$$
\end{esempio}

\paragraph{Fattore di normalizzazione}
Al fine di rendere DCG normalizzata, ovvero a valori in $\left[0, 1\right]$, si introduce il fattore di
normalizzazione, chiamato  $Z_{k, q}$. Il pedice $k,q$ indica che esso può dipendere dalla lunghezza
della lista e dalla query.
Un esempio di normalizzazione potrebbe essere quello di usare l'$i$DCG (la $i$ sta per ideale),
cioè il valore di DCG se i risultati fossero ordinati correttamente.

\begin{esempio}\label{eg:ndcg}
	 Per rendere la funzione dell'esempio \ref{eg:dcg}  normalizzata, si può calcolare
	 il fattore $Z_{k,q}$ come segue.
	 L'ordinamento ideale per i documenti potrebbe essere $\mathcal{L}_i = \left\{r_1, r_4, r_3, r_2\right\}$,
	 oppure tutte le permutazioni di esso per cui $\rel_B(\mathcal{L}_i)= \left\{1,1,0,0\right\}$.
	 $$
	 Z_{k,q} = iDCG = \frac{2^{1} - 1}{1} + \frac{2^{1} - 1}{1.58} + \frac{2^{0} - 1}{2} + \frac{2^{0} - 1}{2.32} = 1.63
	 $$
	 
	 dunque NDCG è pari a:
	 $$
	 NDCG = \frac{1.43}{1.63} = 0.88
	 $$
\end{esempio}

Attraverso questa misura abbiamo ottenuto un meccanismo di valutazione che è in grado di tenere in considerazione
sia il problema della quantità di dati, sia quello dell'ordinamento; inoltre  non viene
usato direttamente il valore della funzione di ranking, ma l'ordinamento dei risultati.
Ciò ci consente dunque di essere in grado di valutare qualsiasi motore di ricerca
senza fare restrizioni sulla funzione di ranking.
